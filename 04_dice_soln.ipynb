{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bite Size Bayes\n",
    "\n",
    "Copyright 2020 Allen B. Downey\n",
    "\n",
    "License: [Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "[In the previous notebook](https://colab.research.google.com/github/AllenDowney/BiteSizeBayes/blob/master/03_cookie.ipynb) \n",
    "\n",
    "$P(A|B) = \\frac{P(A) P(B|A)}{P(B)}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More hypotheses\n",
    "\n",
    "One nice thing about the table method is that it works with more than two hypotheses.  As an example, let' do another version of the cookie problem.\n",
    "\n",
    "Suppose you have five bowls:\n",
    "\n",
    "* Bowl 0 contains no vanilla cookies.\n",
    "\n",
    "* Bowl 1 contains 25% vanilla cookies.\n",
    "\n",
    "* Bowl 2 contains 50% vanilla cookies.\n",
    "\n",
    "* Bowl 3 contains 75% vanilla cookies.\n",
    "\n",
    "* Bowl 4 contains 100% vanilla cookies.\n",
    "\n",
    "Now suppose we choose a bowl at random and then choose a cookie, and we get a vanilla cookie.  What is the posterior probability that we chose each bowl?\n",
    "\n",
    "Here's a table that represents the five hypotheses and their prior probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prior\n",
       "0    0.2\n",
       "1    0.2\n",
       "2    0.2\n",
       "3    0.2\n",
       "4    0.2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table = pd.DataFrame()\n",
    "table['prior'] = 1/5, 1/5, 1/5, 1/5, 1/5\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihoods of drawing a vanilla cookie from each bowl is the given proportion of vanilla cookies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prior  likelihood\n",
       "0    0.2        0.00\n",
       "1    0.2        0.25\n",
       "2    0.2        0.50\n",
       "3    0.2        0.75\n",
       "4    0.2        1.00"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table['likelihood'] = 0, 0.25, 0.5, 0.75, 1\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have priors and likelihoods, the remaining steps are always the same.  We compute the unnormalized posteriors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prior  likelihood  unnorm\n",
       "0    0.2        0.00    0.00\n",
       "1    0.2        0.25    0.05\n",
       "2    0.2        0.50    0.10\n",
       "3    0.2        0.75    0.15\n",
       "4    0.2        1.00    0.20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table['unnorm'] = table['prior'] * table['likelihood']\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the total probability of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_data = table['unnorm'].sum()\n",
    "prob_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then divide through to get the normalized posteriors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnorm</th>\n",
       "      <th>posterior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prior  likelihood  unnorm  posterior\n",
       "0    0.2        0.00    0.00        0.0\n",
       "1    0.2        0.25    0.05        0.1\n",
       "2    0.2        0.50    0.10        0.2\n",
       "3    0.2        0.75    0.15        0.3\n",
       "4    0.2        1.00    0.20        0.4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table['posterior'] = table['unnorm'] / prob_data\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two things you might notice about these results:\n",
    "\n",
    "1. One of the hypotheses has a posterior probability of 0, which means it has been ruled out entirely.  And that makes sense: Bowl 0 contains no vanilla cookies, so if we get a vanilla cookie, we know it's not from Bowl 0.\n",
    "\n",
    "2. The posterior probabilities form a straight line.  We can see this more clearly by plotting the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "table['posterior'].plot(kind='bar')\n",
    "plt.xlabel('Bowl #')\n",
    "plt.ylabel('Posterior probability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**  Use the table method to solve the following problem and plot the results as a bar chart.\n",
    "\n",
    ">The blue M&M was introduced in 1995.  Before then, the color mix in a bag of plain M&Ms was (30% Brown, 20% Yellow, 20% Red, 10% Green, 10% Orange, 10% Tan).  \n",
    ">\n",
    ">Afterward it was (24% Blue , 20% Green, 16% Orange, 14% Yellow, 13% Red, 13% Brown).\n",
    ">\n",
    ">A friend of mine has two bags of M&Ms, and he tells me that one is from 1994 and one from 1996.  He won't tell me which is which, but he gives me one M&M from each bag.  One is yellow and one is green.  What is the probability that the yellow M&M came from the 1994 bag?\n",
    "\n",
    "Hint: If the yellow came from 1994, the green must have come from 1996.  The likelihood of this combination is (0.2)(0.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnorm</th>\n",
       "      <th>posterior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.259259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prior  likelihood  unnorm  posterior\n",
       "1994    0.5       0.040   0.020   0.740741\n",
       "1996    0.5       0.014   0.007   0.259259"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "\n",
    "table = pd.DataFrame(index=['1994', '1996'])\n",
    "table['prior'] = 1/2, 1/2\n",
    "table['likelihood'] = (0.2 * 0.2), (0.14 * 0.1)\n",
    "table['unnorm'] = table['prior'] * table['likelihood']\n",
    "prob_data = table['unnorm'].sum()\n",
    "table['posterior'] = table['unnorm'] / prob_data\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "table['posterior'].plot(kind='bar')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Posterior probability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why does this work?\n",
    "\n",
    "At this point you might be bothered by a missing piece: I have not really explained how the table method works.  I'll do that now, making two arguments:\n",
    "\n",
    "1. First, I'll show that it makes sense to normalize the posteriors so they add up to 1.\n",
    "\n",
    "2. Then I'll show that this step is consistent with Bayes's Theorem, because the total of the unnormalized posteriors is $P(D)$, the total probability of the data.\n",
    "\n",
    "Here's the first argument.  Let's start with Bayes's Theorem:\n",
    "\n",
    "$P(H|D) = P(H) P(D|H)~/~P(D)$\n",
    "\n",
    "Notice that the denominator, $P(D)$, does not depend on $H$, so it is the same for all hypotheses.  If we multiply by $P(D)$ for all hypotheses, we get:\n",
    "\n",
    "$P(H|D) \\sim P(H) P(D|H)$\n",
    "\n",
    "Which says that the posterior probabilities *are proportional to* the unnormalized posteriors.  In other words, if we leave out $P(D)$, we get the proportions right, but not the total.\n",
    "\n",
    "Then how do we figure out the total?  Well, in this example we can see that one of the hypotheses must be true, and only one.  So we know that the posterior probabilities have to add up to 1.  When we divide through by the sum of the unnormalized posteriors, we make the posteriors add up to 1.\n",
    "\n",
    "That's the first argument.  I hope it makes some sense, but if you don't find it entirely satisfying, keep going."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total probability\n",
    "\n",
    "To make the second argument, we'll need two more theorems of probability: disjunction and the aptly-named \"Law of Total Probability\".\n",
    "\n",
    "Let me start with an example: \n",
    "\n",
    ">Suppose you have a 4-sided die and a 6-sided die.  You choose one at random and roll it.  What is the probability of getting a 1?\n",
    "\n",
    "To answer that, I'll define two hypotheses and a datum:\n",
    "\n",
    "* $H_4$: You chose the 4-sided die.\n",
    "\n",
    "* $H_6$: You chose the 6-sided die.\n",
    "\n",
    "* $D$: You rolled a 1.\n",
    "\n",
    "One a 4-sided die, the probability of rolling 1 is $1/4$.  And on a 6-sided die it is $1/6$.  So we can write the conditional probabilities:\n",
    "\n",
    "$P(D|H_4) = 1/4$\n",
    "\n",
    "$P(D|H_6) = 1/6$\n",
    "\n",
    "And we if the probability of choosing either die is equal, we know the prior probabilities:\n",
    "\n",
    "$P(H_4) = 1/2$\n",
    "\n",
    "$P(H_6) = 1/2$\n",
    "\n",
    "But what is the total probability of the data, $P(D)$?\n",
    "\n",
    "At this point your intuition might tell you that it is the weighted sum of the conditional probabilities:\n",
    "\n",
    "$P(D) = P(H_4)P(D|H_4) + P(H_6)P(D|H_6)$\n",
    "\n",
    "Which is\n",
    "\n",
    "$P(D) = (1/2)(1/4) + (1/2)(1/6)$\n",
    "\n",
    "Which is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20833333333333331"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1/2)*(1/4) + (1/2)*(1/6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's correct.  But if your intuition did not tell you that, or if you would like to see something closer to a proof, keep going."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disjunction\n",
    "\n",
    "In this example, we can describe the outcome in terms of logical operators like this:\n",
    "\n",
    "> The outcome is 1 if you choose the 4-sided die **and** roll 1 **or** you roll the 6-sided die **and** roll 1.\n",
    "\n",
    "Or using math notation, $D$ is true if:\n",
    "\n",
    "$(H_4 ~and~ D) ~or~ (H_6 ~and~ D)$\n",
    "\n",
    "We've already seen the $and$ operator, also known as \"conjunction\", but we have not yet seen the $or$ operator, which is also known as \"disjunction\"?\n",
    "\n",
    "For that, we a new rule, which I'll call **Theorem 4**:\n",
    "\n",
    "$P(A ~or~ B) = P(A) + P(B) - P(A ~and~ B)$\n",
    "\n",
    "To see why that's true, let's take a look at the Venn diagram:\n",
    "\n",
    "<img width=\"200\" src=\"https://github.com/AllenDowney/BiteSizeBayes/raw/master/theorem4_venn_diagram.png\">\n",
    "\n",
    "What we want is the total of the red, blue, and purple regions.  If we add $P(A)$ and $P(B)$, we get the red and blue regions right, but we double-count the purple region.  So we have to subtract off one purple region, which is $P(A ~and~ B)$\n",
    "\n",
    "In the dice example, $H_4$ and $H_6$ are \"exclusive\", which means only one of them can be true, so the purple region is 0.  Therefore:\n",
    "\n",
    "$P(D) = P(H_4 ~and~ D) + P(H_4 ~and~ D) - 0$\n",
    "\n",
    "Now we can use **Theorem 2** to replace the conjunctions with conditonal probabilities:\n",
    "\n",
    "$P(D) = P(H_4)~P(D|H_4) + P(H_6)~P(D|H_6)$\n",
    "\n",
    "By a similar argument, we can show that this is true for any number of hypotheses.  For example, if we add an 8-sided die to the mix, we can write:\n",
    "\n",
    "$P(D) = P(H_4)~P(D|H_4) + P(H_6)~P(D|H_6) + P(H_8)~P(D|H_8)$\n",
    "\n",
    "And more generally, with any number of hypotheses $H_i$:\n",
    "\n",
    "$P(D) = \\sum_i P(H_i)~P(D|H_i)$\n",
    "\n",
    "Which shows that the total probability of the data is the sum of the unnormalized posteriors.\n",
    "\n",
    "And that's why the table method works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing total probability\n",
    "\n",
    "Let's get back to the original question:\n",
    "\n",
    ">Suppose you have a 4-sided die and a 6-sided die.  You choose one at random and roll it.  What is the probability of getting a 1?\n",
    "\n",
    "To compute the answer, we can use a Bayes table.  Here are the priors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H4</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H6</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prior\n",
       "H4    0.5\n",
       "H6    0.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(index=['H4', 'H6'])\n",
    "table['prior'] = 1/2, 1/2\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the likelihoods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prior  likelihood\n",
       "H4    0.5    0.250000\n",
       "H6    0.5    0.166667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table['likelihood'] = 1/4, 1/6\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute the unnormalized posteriors in the usual way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prior  likelihood    unnorm\n",
       "H4    0.5    0.250000  0.125000\n",
       "H6    0.5    0.166667  0.083333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table['unnorm'] = table['prior'] * table['likelihood']\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the total probability of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20833333333333331"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_data = table['unnorm'].sum()\n",
    "prob_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's what we got when we solved the problem by hand, so that's good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Suppose you have a 4-sided, 6-sided, and 8-sided die.  You choose one at random and roll it, what is the probability of getting a 1?\n",
    "\n",
    "Do you expect it to be higher or lower than in the previous example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnorm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H4</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H6</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H8</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prior  likelihood    unnorm\n",
       "H4  0.333333    0.250000  0.083333\n",
       "H6  0.333333    0.166667  0.055556\n",
       "H8  0.333333    0.125000  0.041667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "\n",
    "table = pd.DataFrame(index=['H4', 'H6', 'H8'])\n",
    "table['prior'] = 1/3, 1/3, 1/3\n",
    "table['likelihood'] = 1/4, 1/6, 1/8\n",
    "table['unnorm'] = table['prior'] * table['likelihood']\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18055555555555555"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "\n",
    "prob_data = table['unnorm'].sum()\n",
    "prob_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and inference\n",
    "\n",
    "In the previous section, we use a Bayes table to solve this problem:\n",
    "\n",
    "> Suppose you have a 4-sided die and a 6-sided die.  You choose one at random and roll it.  What is the probability of getting a 1?\n",
    "\n",
    "I'll call this a \"prediction problem\" because we are given a scenario and asked to predict the outcome.\n",
    "\n",
    "Now let's solve a closely-related problem:\n",
    "\n",
    "> Suppose you have a 4-sided die and a 6-sided die.  You choose one at random, roll it, and get a 1.  What is the probability that the die you rolled is 4-sided?\n",
    "\n",
    "I'll call this an \"inference problem\" because we are given the outcome and asked to figure out, or infer, which die was rolled.\n",
    "\n",
    "Here's a solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnorm</th>\n",
       "      <th>posterior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prior  likelihood    unnorm  posterior\n",
       "H4    0.5    0.250000  0.125000        0.6\n",
       "H6    0.5    0.166667  0.083333        0.4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(index=['H4', 'H6'])\n",
    "table['prior'] = 1/2, 1/2\n",
    "table['likelihood'] = 1/4, 1/6\n",
    "table['unnorm'] = table['prior'] * table['likelihood']\n",
    "prob_data = table['unnorm'].sum()\n",
    "table['posterior'] = table['unnorm'] / prob_data\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the outcome is a 1, there is a 50% chance the die you rolled was 4-sided.\n",
    "\n",
    "As this example shows, prediction and inference closely-related problems, and we can use the same methods for both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** This exercise has two parts:\n",
    "\n",
    "1. Suppose you have a 4-sided, 6-sided, 8-sided, and 12-sided die.  You choose one at random and roll it.  What is the probabily of getting a 1?\n",
    "\n",
    "2. Now suppose the outcome is a 1. What is the probability that the die you rolled is 4-sided?  And what are the posterior probabilities for the other dice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15625"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "\n",
    "table = pd.DataFrame(index=['H4', 'H6', 'H8', 'H12'])\n",
    "table['prior'] = 1/4, 1/4, 1/4, 1/4\n",
    "table['likelihood'] = 1/4, 1/6, 1/8, 1/12\n",
    "table['unnorm'] = table['prior'] * table['likelihood']\n",
    "prob_data = table['unnorm'].sum()\n",
    "prob_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnorm</th>\n",
       "      <th>posterior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H6</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H8</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H12</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     prior  likelihood    unnorm  posterior\n",
       "H4    0.25    0.250000  0.062500   0.400000\n",
       "H6    0.25    0.166667  0.041667   0.266667\n",
       "H8    0.25    0.125000  0.031250   0.200000\n",
       "H12   0.25    0.083333  0.020833   0.133333"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "\n",
    "table['posterior'] = table['unnorm'] / prob_data\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
