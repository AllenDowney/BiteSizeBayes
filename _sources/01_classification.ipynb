{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "Recidivism Case Study\n",
    "\n",
    "Copyright 2020 Allen B. Downey\n",
    "\n",
    "License: [Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This is the first in a series of notebooks that make up a [case study on classification and algorithmic fairness](https://allendowney.github.io/RecidivismCaseStudy/).\n",
    "This case study is part of the [*Elements of Data Science*](https://allendowney.github.io/ElementsOfDataScience/) curriculum.\n",
    "\n",
    "This case study is related to \"[Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)\", an article published by ProPublica in 2015.  The article explores the use of predictive algorithms in the criminal justice system.  The arguments presented in the article are statistical; specifically they are related to binary classification.\n",
    "\n",
    "The goal of these notebooks is to replicate the analysis reported in the article and to  review ways to evaluate binary classification algorithms.  \n",
    "\n",
    "* In this notebook, we start with the confusion matrix and the metrics that are derived from it, including accuracy, sensitivity, specificity, predictive value, false positive rate, and false negative rate.\n",
    "\n",
    "* In the next notebook, I review the arguments made in a response article published in the Washington Post.  I compute and interpret calibration curves, and explore the trade-offs between predictive value and error rates.\n",
    "\n",
    "* In the third notebook, I apply the same analysis to evaluate the performance of classification for male and female defendants.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Bias\n",
    "\n",
    "We will start by replicating the analysis reported in\n",
    "\"[Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)\", by Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner, and published by [ProPublica](https://www.propublica.org) in May 2016.\n",
    "\n",
    "This article is about a statistical tool called COMPAS which is used in the criminal justice systems of some states to inform decisions about which defendants should be released on bail before trial, how long convicted defendants should be imprisoned, and whether prisoners should be released on probation.\n",
    "\n",
    "COMPAS uses information about defendants to generate a \"risk score\" which is intended to quantify the risk that the defendant would commit another crime if released."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors of the ProPublica article used public data to assess the accuracy of those risk scores.  They explain:\n",
    "\n",
    "> We obtained the risk scores assigned to more than 7,000 people arrested in Broward County, Florida, in 2013 and 2014 and checked to see how many were charged with new crimes over the next two years, the same benchmark used by the creators of the algorithm.\n",
    "\n",
    "[In their notebook](https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb), they explain in more detail:\n",
    "\n",
    "> We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility.\n",
    ">\n",
    "> [...]\n",
    ">\n",
    "> Next, we sought to determine if a person had been charged with a new crime subsequent to the crime for which they were COMPAS screened. We did not count traffic tickets and some municipal ordinance violations as recidivism. We did not count as recidivists people who were arrested for failing to appear at their court hearings, or people who were later charged with a crime that occurred prior to their COMPAS screening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not familiar with the word \"recidivism\", it means \"[a tendency to relapse into a previous condition or mode of behavior, especially relapse into criminal behavior](https://www.merriam-webster.com/dictionary/recidivism)\".\n",
    "\n",
    "In this context, a person is a \"recidivist\" if they are *charged* with another crime within two years of release.  However, note that there is a big difference between *committing* another crime and being *charged* with another crime.  We will come back to this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors of the ProPublica article use this data to evaluate how well COMPAS predicts the risk that a defendant will be charged with another crime within two years of their release.\n",
    "\n",
    "Among their findings, they report:\n",
    "\n",
    "> ... the algorithm was somewhat more accurate than a coin flip. Of those deemed likely to re-offend, 61 percent were arrested for any subsequent crimes within two years.\n",
    "> \n",
    "> ... In forecasting who would re-offend, the algorithm made mistakes with black and white defendants at roughly the same rate but in very different ways.\n",
    ">\n",
    "> * The formula was particularly likely to falsely flag black defendants as future criminals, wrongly labeling them this way at almost twice the rate as white defendants.\n",
    ">\n",
    "> * White defendants were mislabeled as low risk more often than black defendants.\n",
    "\n",
    "This discrepancy suggests that the use of COMPAS in the criminal justice system is racially biased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ProPublica article was published, it has been widely discussed in the media, and a number of researchers have published responses.  In order to evaluate the original article and the responses it provoked, there are some technical issues you need to understand.  My goal for these notebooks is to help you analyze the arguments and interpret the statistics they are based on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The ProPublica article writes \"white\" and \"black\" starting with lower-case letters, which was the most common style in 2016.  But things are changing.  As I revise this document in 2021, many style guides now suggest that \"Black\" should be capitalized, and some suggest that \"White\" should, too.\n",
    "For now, I will follow the convention of the original article, but I will revisit this decision in future editions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The authors of \"Machine Bias\" published their data and analysis in [this repository](https://github.com/propublica/compas-analysis).\n",
    "The terms of use for the data [are here](https://www.propublica.org/datastore/terms).  In compliance with those terms, I am not redistributing the data.\n",
    "The following cell downloads the data file we'll use directly from their repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import basename, exists\n",
    "\n",
    "def download(url):\n",
    "    filename = basename(url)\n",
    "    if not exists(filename):\n",
    "        from urllib.request import urlretrieve\n",
    "        local, _ = urlretrieve(url, filename)\n",
    "        print('Downloaded ' + local)\n",
    "\n",
    "download('https://github.com/propublica/compas-analysis/raw/master/' +\n",
    "         'compas-scores-two-years.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell reads the data file and displays the number of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7214, 53)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp = pd.read_csv('compas-scores-two-years.csv')\n",
    "cp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset includes 7214 rows, one for each defendant, and 53 columns.  Here are the names of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
       "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
       "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
       "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
       "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
       "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
       "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
       "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
       "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
       "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
       "       'decile_score.1', 'score_text', 'screening_date',\n",
       "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
       "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
       "       'start', 'end', 'event', 'two_year_recid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have not found documentation for the columns in this dataset; we have to infer what they mean based on the column names and how they are used in the original analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Confusion Matrix\n",
    "\n",
    "The authors of \"Machine Bias\" describe their analysis in more detail in [this article](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm).  It includes this table, which summarizes many of the results they report:\n",
    "\n",
    "<img width=\"100%\" src='https://raw.githubusercontent.com/AllenDowney/RecidivismCaseStudy/master/machine_bias_table.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table summarizes results for all defendants and two subgroups: defendants classified as white (\"Caucasian\" in the original dataset) and black (\"African-American\").\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each group, the summary includes a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) and a number of metrics, including\n",
    "\n",
    "* FP rate: false positive rate\n",
    "* FN rate: false negative rate\n",
    "* PPV: positive predictive value\n",
    "* NPV: negative predictive value\n",
    "* LR+: positive likelihood ratio \n",
    "* LR-: negative likelihood ratio \n",
    "\n",
    "I will explain what these metrics mean and how to compute them, and we'll replicate the results in this table.\n",
    "\n",
    "But first let's examine the data and compute some recoded variables.\n",
    "\n",
    "The following function displays the values in a Series and the number of times each value appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def values(series):\n",
    "    \"\"\"Count the values and sort.\n",
    "    \n",
    "    series: pd.Series\n",
    "    \n",
    "    returns: series mapping from values to frequencies\n",
    "    \"\"\"\n",
    "    return series.value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the values of `decile_score` which is the output of the COMPAS algorithm.  `1` is the lowest risk category; `10` is the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     1440\n",
       "2      941\n",
       "3      747\n",
       "4      769\n",
       "5      681\n",
       "6      641\n",
       "7      592\n",
       "8      512\n",
       "9      508\n",
       "10     383\n",
       "Name: decile_score, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values(cp['decile_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that COMPAS is not a binary classifier; that is, it does not predict that a defendant will or will not recidivate.  Rather, it gives each defendant a score that is intended to reflect the risk that they will recidivate.\n",
    "\n",
    "In order to evaluate the performance of COMPAS, the authors of the ProPublica article chose a threshold, `4`, and define decile scores at or below the threshold to be \"low risk\", and scores above the threshold to be \"high risk\".\n",
    "\n",
    "Their choice of the threshold is arbitrary.  Later, we will see what happens with other choices, but we'll start by replicating the original analysis.\n",
    "\n",
    "`high_risk` is a Boolean Series that's `True` for respondents with a decile score greater than 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3897\n",
       "True     3317\n",
       "Name: HighRisk, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_risk = (cp['decile_score'] > 4)\n",
    "high_risk.name = 'HighRisk'\n",
    "values(high_risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column `two_year_recid` indicates whether a defendant was charged with another crime during a two year period, after the original charge, when they were not in a correctional facility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3963\n",
       "1    3251\n",
       "Name: two_year_recid, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values(cp['two_year_recid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`new_charge_2` is a Boolean Series that is `True` for defendants who were charged with another crime within two years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3963\n",
       "True     3251\n",
       "Name: NewCharge2, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_charge_2 = (cp['two_year_recid'] == 1)\n",
    "new_charge_2.name = 'NewCharge2'\n",
    "values(new_charge_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we make a cross-tabulation of `new_charge_2` and `high_risk`, the result is a DataFrame that indicates how many defendants are in each of four groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>HighRisk</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewCharge2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>2681</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1216</td>\n",
       "      <td>2035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "HighRisk    False  True \n",
       "NewCharge2              \n",
       "False        2681   1282\n",
       "True         1216   2035"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(new_charge_2, high_risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table is called a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) or error matrix.  Reading from left to right and top to bottom, the elements of the matrix show the number of respondents who were:\n",
    "\n",
    "* Classified as low risk and not charged with a new crime: there were 2681 **true negatives**; that is, cases where the test was negative (not high risk) and the prediction turned out to be correct (no new charge).\n",
    "\n",
    "* High risk and not charged: there were 1282 **false positives**, cases where the test was positive and the prediction was incorrect.\n",
    "\n",
    "* Low risk and charged: there were 1216 **false negatives**, cases where the test was negative (low risk) and the prediction was incorrect (the defendant was charged with a new crime).\n",
    "\n",
    "* High risk and charged: there were 2035 **true positives**, cases where the test was positive and the prediction was correct.\n",
    "\n",
    "The values in this matrix are consistent with the values in the ProPublica article, so we can confirm that we are reading the data and replicating their analysis correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go on, I'll also check the confusion matrices for white and black defendants.\n",
    "\n",
    "Here are the values of `race`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "African-American    3696\n",
       "Asian                 32\n",
       "Caucasian           2454\n",
       "Hispanic             637\n",
       "Native American       18\n",
       "Other                377\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values(cp['race'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a Boolean Series that's true for white defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    4760\n",
       "True     2454\n",
       "Name: white, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white = (cp['race'] == 'Caucasian')\n",
    "white.name = 'white'\n",
    "values(white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the confusion matrix for white defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>HighRisk</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewCharge2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>1139</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>461</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "HighRisk    False  True \n",
       "NewCharge2              \n",
       "False        1139    349\n",
       "True          461    505"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(new_charge_2[white], high_risk[white])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`black` is a Boolean Series that is `True` for black defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3518\n",
       "True     3696\n",
       "Name: black, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black = (cp['race'] == 'African-American')\n",
    "black.name = 'black'\n",
    "values(black)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is the confusion matrix for black defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>HighRisk</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewCharge2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>990</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>532</td>\n",
       "      <td>1369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "HighRisk    False  True \n",
       "NewCharge2              \n",
       "False         990    805\n",
       "True          532   1369"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(new_charge_2[black], high_risk[black])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these results are consistent with the ProPublica article.\n",
    "\n",
    "However, before we go on, I want to address an important issue with this dataset: data bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data bias\n",
    "\n",
    "Systems like COMPAS are trying to predict whether a defendant will *commit* another crime if released.  But the dataset reports whether a defendant was *charged* with another crime.\n",
    "\n",
    "Not everyone who commits a crime gets charged (not even close).  The probability of getting charged for a particular crime depends on the type of crime and location; the presence of witnesses and their willingness to work with police; the decisions of police about where to patrol, what crimes to investigate, and who to arrest; and decisions of prosecutors about who to charge.\n",
    "\n",
    "It is likely that every one of these factors depends on the race of the defendant.  In this dataset, the prevalence of *new charges* is higher for black defendants, but that doesn't necessarily mean that the prevalence of *new crimes* is higher.  \n",
    "\n",
    "If the dataset is affected by racial bias in the probability of being charged, prediction algorithms like COMPAS will be biased, too.  In discussions of whether and how these systems should be used in the criminal justice system, this is an important issue.  \n",
    "\n",
    "However, I am going to put it aside *for now* in order to focus on understanding the arguments posed in the ProPublica article and the metrics they are based on.  For the rest of this notebook I will take the \"recidivism rates\" in the dataset at face value; but I will try to be clear about that they mean (and don't mean)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arranging the confusion matrix\n",
    "\n",
    "In the previous section I arranged the confusion matrix to be consistent with the ProPublica article, to make it easy to check for consistency.\n",
    "\n",
    "In general, there are many possible ways to arrange a confusion matrix: you can put the predictions along the columns and the actual conditions along the rows, or the other way around, and you can sort the rows and columns in either order.\n",
    "\n",
    "There is no universal standard arrangement, but the one that seems to be most common is the one on the [confusion matrix Wikipedia page](https://en.wikipedia.org/wiki/Confusion_matrix), which looks like this:\n",
    "\n",
    "<img width=400, src='https://raw.githubusercontent.com/AllenDowney/RecidivismCaseStudy/master/confusion_matrix1.png'>\n",
    "\n",
    "In this arrangement:\n",
    "\n",
    "* The predictions are down the rows.\n",
    "\n",
    "* The actual results are across the columns.\n",
    "\n",
    "* The rows and columns are sorted so true positives are in the upper left and true negatives are in the lower right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of the ProPublica article:\n",
    "\n",
    "* \"Predicted condition positive\" means the defendant is classified as high risk.\n",
    "\n",
    "* \"Predicted condition negative\" means low risk.\n",
    "\n",
    "* \"Condition positive\" means the defendant was charged with a new crime (recidivated).\n",
    "\n",
    "* \"Condition negative\" means they were not charged (survived).\n",
    "\n",
    "The following function makes a confusion matrix with this arrangement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_matrix(cp, threshold=4):\n",
    "    \"\"\"Make a confusion matrix.\n",
    "\n",
    "    cp: DataFrame\n",
    "    threshold: default is 4\n",
    "\n",
    "    returns: DataFrame containing the confusion matrix\n",
    "    \"\"\"\n",
    "    a = np.where(cp['decile_score'] > threshold,\n",
    "                 'Positive',\n",
    "                 'Negative')\n",
    "    high_risk = pd.Series(a, name='Predicted')\n",
    "\n",
    "    a = np.where(cp['two_year_recid'] == 1,\n",
    "                 'Condition',\n",
    "                 'No Condition')\n",
    "    new_charge_2 = pd.Series(a, name='Actual')\n",
    "\n",
    "    matrix = pd.crosstab(high_risk, new_charge_2)\n",
    "    matrix.sort_index(axis=0, ascending=False, inplace=True)\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the confusion matrices for white defendants, black defendants, and all defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>Condition</th>\n",
       "      <th>No Condition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>505</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>461</td>\n",
       "      <td>1139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual     Condition  No Condition\n",
       "Predicted                         \n",
       "Positive         505           349\n",
       "Negative         461          1139"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_white = make_matrix(cp[white])\n",
    "matrix_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>Condition</th>\n",
       "      <th>No Condition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>1369</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>532</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual     Condition  No Condition\n",
       "Predicted                         \n",
       "Positive        1369           805\n",
       "Negative         532           990"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_black = make_matrix(cp[black])\n",
    "matrix_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>Condition</th>\n",
       "      <th>No Condition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>2035</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>1216</td>\n",
       "      <td>2681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual     Condition  No Condition\n",
       "Predicted                         \n",
       "Positive        2035          1282\n",
       "Negative        1216          2681"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_all = make_matrix(cp)\n",
    "matrix_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "Based on these results, how accurate is COMPAS as a binary classifier?  Well, it turns out that there are a *lot* of ways to answer that question.\n",
    "\n",
    "One of the simplest ones is overall **accuracy**, which is the fraction (or percentage) of correct predictions.\n",
    "\n",
    "To compute accuracy, it is convenient to extract from the confusion matrix the number of true positives, false positives, false negatives, and true negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, fn, tn = matrix_all.to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of true predictions is `tp + tn`.\n",
    "\n",
    "The number of false predictions is `fp + fn`.\n",
    "\n",
    "So we can compute the fraction of true predictions like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent(x, y):\n",
    "    \"\"\"Compute the percentage `x/(x+y)*100`.\"\"\"\n",
    "    return x / (x+y) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.37288605489326"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = percent(tp + tn, fp + fn)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a way to evaluate a binary classifier, accuracy does not distinguish between true positives and true negatives, or false positives and false negatives.\n",
    "\n",
    "But it is often important to make these distinctions, because the benefits of true predictions and true negatives might be different, and the costs of false positives and false negatives might be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive value\n",
    "\n",
    "One way to make these distinctions is to compute the \"predictive value\" of positive and negative tests. \n",
    "\n",
    "* **Positive predictive value (PPV)** is the fraction of positive tests that are correct.\n",
    "\n",
    "* **Negative predictive value (NPV)** is the fraction of negative tests that are correct.\n",
    "\n",
    "In this example, PPV is the fraction of high risk defendants who were charged with a new crime.  NPV is the fraction of low risk defendants who \"survived\" a two year period without being charged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function takes a confusion matrix and computes these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictive_value(m):\n",
    "    \"\"\"Compute positive and negative predictive value.\n",
    "    \n",
    "    m: confusion matrix\n",
    "    \"\"\"\n",
    "    tp, fp, fn, tn = m.to_numpy().flatten()\n",
    "    ppv = percent(tp, fp)\n",
    "    npv = percent(tn, fn)\n",
    "    return ppv, npv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the predictive values for all defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61.350618028338864, 68.79651013600206)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppv, npv = predictive_value(matrix_all)\n",
    "ppv, npv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among all defendants, a positive test is correct about 61% of the time; a negative test result is correct about 69% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity and specificity\n",
    "\n",
    "Another way to characterize the accuracy of a test is to compute \n",
    "\n",
    "* **Sensitivity**, which is the probability of predicting correctly when the condition is present, and \n",
    "\n",
    "* **Specificity**, which is the probability of predicting correctly when the condition is absent.\n",
    "\n",
    "A test is \"sensitive\" if it detects the positive condition. \n",
    "In this example, sensitivity is the fraction of recidivists who were correctly classified as high risk.\n",
    "\n",
    "A test is \"specific\" if it identifies the negative condition.  In this example, specificity is the fraction of non-recidivists who were correctly classified as low risk.\n",
    "\n",
    "The following function takes a confusion matrix and computes sensitivity and specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sens_spec(m):\n",
    "    \"\"\"Compute sensitivity and specificity.\n",
    "    \n",
    "    m: confusion matrix\n",
    "    \"\"\"\n",
    "    tp, fp, fn, tn = m.to_numpy().flatten()\n",
    "    sens = percent(tp, fn)\n",
    "    spec = percent(tn, fp)\n",
    "    return sens, spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are sensitivity and specificity for all defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62.59612426945556, 67.65076961897553)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens, spec = sens_spec(matrix_all)\n",
    "sens, spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we evaluate COMPAS as a binary classifier, it is a little more specific than sensitive:\n",
    "\n",
    "* About 63% of the recidivists were classified as high risk.\n",
    "\n",
    "* About 68% of the non-recidivists were classified as low risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be hard to keep all of these metrics straight, especially when you are learning about them for the first time.  The following diagram [from Wikipedia](https://en.wikipedia.org/wiki/Confusion_matrix) might help:\n",
    "\n",
    "<img width=800, src='https://raw.githubusercontent.com/AllenDowney/RecidivismCaseStudy/master/confusion_matrix2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPV and sensitivity are similar in the sense that they both have true positives in the numerator.  The difference is the denominator:\n",
    "\n",
    "* PPV is the ratio of true positives to all positive tests.  So it answers the question, \"Of all positive tests, how many are correct?\"\n",
    "\n",
    "* Sensitivity is the ratio of true positives to all positive conditions.  So it answers the question \"Of all positive conditions, how many are detected?\"\n",
    "\n",
    "Similarly, NPV and sensitivity both have true negatives in the numerator, but:\n",
    "\n",
    "* NPV is the ratio of true negatives to all negative tests.  It answers, \"Of all negative tests, how many are correct?\"\n",
    "\n",
    "* Specificity is the ratio of true negatives to all negative conditions.  It answers, \"Of all negative conditions, how many are classified correctly?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False positive and negative rates\n",
    "\n",
    "The ProPublica article reports PPV and NPV, but instead of sensitivity and specificity, it reports their complements:\n",
    "\n",
    "* **False positive rate**, which is the ratio of false positives to all negative conditions.  It answers, \"Of all negative conditions, how many are misclassified?\" \n",
    "\n",
    "* **False negative rate**, which is the ratio of false negatives to all positive conditions.  It answers, \"Of all positive conditions, how many are misclassified?\"\n",
    "\n",
    "In this example:\n",
    "\n",
    "* The false positive rate is the fraction of non-recidivists who were classified as high risk.\n",
    "\n",
    "* The false negative rate is the fraction of recidivists who were classified as low risk.\n",
    "\n",
    "The following function takes a confusion matrix and computes false positive and false negative rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rates(m):\n",
    "    \"\"\"Compute false positive and false negative rate.\n",
    "    \n",
    "    m: confusion matrix\n",
    "    \"\"\"\n",
    "    tp, fp, fn, tn = m.to_numpy().flatten()\n",
    "    fpr = percent(fp, tn)\n",
    "    fnr = percent(fn, tp)\n",
    "    return fpr, fnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the error rates for all defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32.349230381024476, 37.40387573054445)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, fnr = error_rates(matrix_all)\n",
    "fpr, fnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FPR is the complement of specificity, which means they have to add up to 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr + spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And FNR is the complement of sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnr + sens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So FPR and FNR are just another way of reporting sensitivity and specificity.\n",
    "In general, I prefer sensitivity and specificity over FPN and FNR because\n",
    "\n",
    "* I think the positive framing is easier to interpret than the negative framing, and\n",
    "\n",
    "* I find it easier to remember what \"sensitivity\" and \"specificity\" mean.\n",
    "\n",
    "I think \"false positive rate\" and \"false negative rate\" are more problematic.  For example, \"false positive rate\" could just as easily mean either\n",
    "\n",
    "1. The fraction of positive tests that are incorrect, or\n",
    "\n",
    "2. The fraction of negative conditions that are misclassified.\n",
    "\n",
    "It is only a convention that the first is called the \"false discovery rate\" and the second is called \"false positive rate\".  I suspect I am not the only one that gets them confused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, here's my recommendation: if you have the choice, generally use PPV, NPV, sensitivity and specificity, and avoid the other metrics.\n",
    "However, since the ProPublica article uses FPR and FNR, I will too.\n",
    "\n",
    "They also report LR+ and LR-, but those are combinations of other metrics and not relevant to the current discussion, so I will ignore them.\n",
    "\n",
    "However, there is one other metric that I think is relevant and not included in the ProPublica tables: prevalence, which is the fraction of all cases where the condition is positive.  In the example, it's the fraction of defendants who recidivate.\n",
    "\n",
    "The following function computes prevalence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prevalence(df):\n",
    "    \"\"\"Compute prevalence.\n",
    "    \n",
    "    m: confusion matrix\n",
    "    \"\"\"\n",
    "    tp, fp, fn, tn = df.to_numpy().flatten()\n",
    "    prevalence = percent(tp+fn, tn+fp)\n",
    "    return prevalence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the prevalence for all defendants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.06515109509287"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev = prevalence(matrix_all)\n",
    "prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 45% of the defendants in this dataset were charged with another crime within two years of their release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All metrics\n",
    "\n",
    "The following function takes a confusion matrix, computes all the metrics, and puts them in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(m, name=''):\n",
    "    \"\"\"Compute all metrics.\n",
    "    \n",
    "    m: confusion matrix\n",
    "    \n",
    "    returns: DataFrame\n",
    "    \"\"\"\n",
    "    fpr, fnr = error_rates(m)\n",
    "    ppv, npv = predictive_value(m)\n",
    "    prev = prevalence(m)\n",
    "    \n",
    "    index = ['FP rate', 'FN rate', 'PPV', 'NPV', 'Prevalence']\n",
    "    df = pd.DataFrame(index=index, columns=['Percent'])\n",
    "    df.Percent = fpr, fnr, ppv, npv, prev\n",
    "    df.index.name = name\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the metrics for all defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All defendants</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP rate</th>\n",
       "      <td>32.349230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN rate</th>\n",
       "      <td>37.403876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>61.350618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>68.796510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevalence</th>\n",
       "      <td>45.065151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Percent\n",
       "All defendants           \n",
       "FP rate         32.349230\n",
       "FN rate         37.403876\n",
       "PPV             61.350618\n",
       "NPV             68.796510\n",
       "Prevalence      45.065151"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(matrix_all, 'All defendants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing these results to the table from ProPublica, it looks like our analysis agrees with theirs.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/AllenDowney/ElementsOfDataScience/master/machine_bias_table.png'>\n",
    "\n",
    "\n",
    "Here are the same metrics for black defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black defendants</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP rate</th>\n",
       "      <td>44.846797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN rate</th>\n",
       "      <td>27.985271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>62.971481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>65.045992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevalence</th>\n",
       "      <td>51.433983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Percent\n",
       "Black defendants           \n",
       "FP rate           44.846797\n",
       "FN rate           27.985271\n",
       "PPV               62.971481\n",
       "NPV               65.045992\n",
       "Prevalence        51.433983"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(matrix_black, 'Black defendants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for white defendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White defendants</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP rate</th>\n",
       "      <td>23.454301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FN rate</th>\n",
       "      <td>47.722567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>59.133489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>71.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevalence</th>\n",
       "      <td>39.364303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Percent\n",
       "White defendants           \n",
       "FP rate           23.454301\n",
       "FN rate           47.722567\n",
       "PPV               59.133489\n",
       "NPV               71.187500\n",
       "Prevalence        39.364303"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(matrix_white, 'White defendants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these results are consistent with those reported in the article, including the headline results:\n",
    "\n",
    "1. The false positive rate for black defendants is substantially higher than for white defendants (45%, compared to 23%).\n",
    "\n",
    "2. The false negative rate for black defendants is substantially lower (28%, compared to 48%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44.84679665738162, 27.985270910047344)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rates(matrix_black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.45430107526882, 47.72256728778468)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rates(matrix_white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words:\n",
    "\n",
    "* Of all people who *will not* recidivate, black defendants are more likely to be be classified as high risk and (if these classifications influence sentencing decisions) more likely to be sent to prison.\n",
    "\n",
    "* Of all people who *will* recidivate, white defendants are more likely to be classified as low risk, and more likely to be released.\n",
    "\n",
    "This seems clearly unfair.\n",
    "\n",
    "However, it turns out that \"fair\" is complicated.  After the ProPublica article, the Washington Post published a response by Sam Corbett-Davies, Emma Pierson, Avi Feller and Sharad Goel: \"[A computer program used for bail and sentencing decisions was labeled biased against blacks. It’s actually not that clear.](https://www.washingtonpost.com/news/monkey-cage/wp/2016/10/17/can-an-algorithm-be-racist-our-analysis-is-more-cautious-than-propublicas/)\".\n",
    "\n",
    "I encourage you to read that article, and then run [the next notebook](https://colab.research.google.com/github/AllenDowney/RecidivismCaseStudy/blob/master/02_calibration.ipynb), where I will unpack their arguments and replicate their analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
